{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cwt_data/cwt_dataset.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cwt_imgs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcwt_data/cwt_dataset.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m#becasue output coefficients are complex\u001b[39;00m\n\u001b[0;32m      2\u001b[0m cwt_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcwt_data/cwt_dataset_labels.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32mc:\\Program Files\\miniconda3\\lib\\site-packages\\numpy\\lib\\npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cwt_data/cwt_dataset.npy'"
     ]
    }
   ],
   "source": [
    "cwt_imgs = np.abs(np.load(r\"cwt_data/cwt_dataset.npy\")) #becasue output coefficients are complex\n",
    "cwt_labels = np.abs(np.load(r\"cwt_data/cwt_dataset_labels.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom dataset class to manage all of the cwt images\n",
    "class CWTDataset(Dataset):\n",
    "    def __init__(self, imgs, labels): #initialize. pass in the images and label\n",
    "        self.imgs = imgs\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self): \n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx): #return img, label pair with index\n",
    "        sel_image = self.imgs[idx]\n",
    "        sel_label = self.labels[idx]\n",
    "        return sel_image, sel_label\n",
    "    \n",
    "cwt_data = CWTDataset(cwt_imgs, cwt_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split cwt_data (Dataset) into 80 20 train/test split\n",
    "train_dataset, test_dataset = random_split(cwt_data, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note the shape of the data\n",
    "#for example CWT, we're looking at 99 scales x 7508 time points per image\n",
    "\n",
    "class CWTNN(nn.Module):\n",
    "    def __init__(self): #define model layers\n",
    "        #first convolve with 6 kernels\n",
    "        #then apply pooling/dimensionality reduction\n",
    "        #then concolve with 16 kernels\n",
    "        #transition to fully connected \"linear\" layers\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 1, kernel_size=3, padding = 1) #one in_channel bc its a grayscale image, one image at a time\n",
    "        self.pool = nn.MaxPool2d(2, 2) #only need to define pooling once, but will get applied after each convolution\n",
    "        self.conv2 = nn.Conv2d(1, 1, kernel_size=3, padding = 1)\n",
    "        self.linear1 = nn.Linear(24 * 748, 120)\n",
    "        self.linear2 = nn.Linear(120, 60)\n",
    "        self.linear3 = nn.Linear(60, 2)  #binary classification   \n",
    "    \n",
    "    def forward(self, x): #define forward pass i.e. how does the model handle inputs?\n",
    "        x = x.float() #convert to float first\n",
    "        #print(\"before\", x.shape)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        #print(\"after first conv, then pool\", x.shape)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print(\"after second conv, then pool\", x.shape)\n",
    "        x = torch.flatten(x, 1) #flatten to input into linear layer\n",
    "        #print(\"after flatten\", x.shape)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        #print(\"after linear 1\", x.shape)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        #print(\"after linear 2\", x.shape)\n",
    "        x = self.linear3(x) \n",
    "        #print(\"after linear 3\", x.shape)\n",
    "        return x\n",
    "\n",
    "        \n",
    "model = CWTNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define additional hyperparameters\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum = 0.9)\n",
    "\n",
    "EPOCHS = 10 #loop 10 times through the entire dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        X, y = data #input image and 0/1 classification\n",
    "        print(X, y.long())\n",
    "        optimizer.zero_grad() #zero out gradients so weights aren't misadjusted\n",
    "        \n",
    "        out = model(X)\n",
    "        loss_val = loss(out, y.long()) #xent loss calculated with output and y \n",
    "        loss_val.backward() #backpropataion\n",
    "        optimizer.step() #adjust weights based on backpropagation\n",
    "        \n",
    "        total_loss += loss_val.item()\n",
    "        print(f\"loss: {loss_val.item()}\")\n",
    "        \n",
    "print(\"finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwt_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.575\n"
     ]
    }
   ],
   "source": [
    "corr = 0\n",
    "n = 0\n",
    "\n",
    "for image, labels in test_loader:\n",
    "    out_label = model(X)\n",
    "    _, pred = torch.max(out_label, 1)\n",
    "    n += labels.size(0) #include all possible oucomes\n",
    "    corr += (pred == labels).sum().item()\n",
    "    \n",
    "print(corr/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
